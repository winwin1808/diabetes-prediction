{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.69763511\n",
      "epoch:  10 loss: 0.54063463\n",
      "epoch:  20 loss: 0.23854996\n",
      "epoch:  30 loss: 0.35226461\n",
      "epoch:  40 loss: 0.35793784\n",
      "epoch:  50 loss: 1.21748435\n",
      "epoch:  60 loss: 0.30541667\n",
      "epoch:  70 loss: 0.35359848\n",
      "epoch:  80 loss: 0.79272026\n",
      "epoch:  90 loss: 0.47297454\n",
      "epoch: 100 loss: 0.12956588\n",
      "epoch: 110 loss: 0.73675698\n",
      "epoch: 120 loss: 0.21876459\n",
      "epoch: 130 loss: 0.43152463\n",
      "epoch: 140 loss: 0.54911917\n",
      "epoch: 150 loss: 0.39269805\n",
      "epoch: 160 loss: 0.13151905\n",
      "epoch: 170 loss: 1.24093246\n",
      "epoch: 180 loss: 0.47870770\n",
      "epoch: 190 loss: 0.25133085\n",
      "epoch: 200 loss: 0.10622872\n",
      "epoch: 210 loss: 0.50334918\n",
      "epoch: 220 loss: 0.14562821\n",
      "epoch: 230 loss: 0.22426742\n",
      "epoch: 240 loss: 0.08275504\n",
      "epoch: 250 loss: 0.17005210\n",
      "epoch: 260 loss: 0.04579890\n",
      "epoch: 270 loss: 0.11834233\n",
      "epoch: 280 loss: 0.14114447\n",
      "epoch: 290 loss: 1.44988430\n",
      "epoch: 299 loss: 0.4115936756\n",
      "ComplexDiabetesLSTM(\n",
      "  (lstm): LSTM(8, 64, num_layers=3, batch_first=True, dropout=0.5)\n",
      "  (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "diabetes_data = pd.read_csv('diabetes.csv')\n",
    "# Data Preparation\n",
    "X = diabetes_data.drop('Outcome', axis=1).values\n",
    "y = diabetes_data['Outcome'].values\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Converting to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1) # Adding an extra dimension for LSTM\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Creating data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# LSTM Model Definition\n",
    "class ComplexDiabetesLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size=64, output_size=1, num_layers=3, dropout_rate=0.5):\n",
    "        super(ComplexDiabetesLSTM, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM with multiple layers and dropout\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=num_layers, batch_first=True, dropout=dropout_rate)\n",
    "\n",
    "        # Additional Linear layers\n",
    "        self.linear1 = nn.Linear(hidden_layer_size, 32)\n",
    "        self.linear2 = nn.Linear(32, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Take the output of the last time step\n",
    "\n",
    "        out = self.dropout(self.relu(self.linear1(lstm_out)))\n",
    "        predictions = torch.sigmoid(self.linear2(out))\n",
    "\n",
    "        return predictions\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "model = ComplexDiabetesLSTM(input_size=X_train.shape[1])\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 300\n",
    "for i in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        y_pred = model(inputs)\n",
    "\n",
    "        single_loss = loss_function(y_pred.view(-1), labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "\n",
    "# Model Summary\n",
    "model.eval()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model parameters\n",
    "torch.save(model.state_dict(), 'diabetes_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7208, Precision: 0.6034, Recall: 0.6364, F1 Score: 0.6195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make sure the model is in evaluation mode\n",
    "model.eval()\n",
    "device = torch.device(\"cpu\")\n",
    "# Lists to store actual and predicted values\n",
    "actuals = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output = model(inputs)\n",
    "        \n",
    "        actuals.extend(labels.view(-1).cpu().numpy())\n",
    "        predictions.extend(torch.round(output.view(-1)).cpu().numpy())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(actuals, predictions)\n",
    "precision = precision_score(actuals, predictions)\n",
    "recall = recall_score(actuals, predictions)\n",
    "f1 = f1_score(actuals, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"62pt\" height=\"39pt\"\n",
       " viewBox=\"0.00 0.00 62.00 39.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 35)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-35 58,-35 58,4 -4,4\"/>\n",
       "<!-- 2402413395504 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2402413395504</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"54,-31 0,-31 0,0 54,0 54,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x22f63e6ddd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Ensure the ComplexDiabetesLSTM class is defined here\n",
    "\n",
    "# Assuming the input size is known and correctly set\n",
    "input_size = 8\n",
    "# Initialize the model\n",
    "model = ComplexDiabetesLSTM(input_size)\n",
    "\n",
    "# Define the device and move the model to the chosen device\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load the saved model state\n",
    "model.load_state_dict(torch.load('diabetes_model.pth', map_location=device))\n",
    "\n",
    "# Create a sample input tensor\n",
    "sample_input = torch.randn(1, 1, input_size).to(device)\n",
    "\n",
    "# Forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y = model(sample_input)\n",
    "\n",
    "# Visualize the computational graph\n",
    "dot = make_dot(y.mean(), params=dict(model.named_parameters()))\n",
    "\n",
    "# If using a Jupyter Notebook, this will display the graph\n",
    "dot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
