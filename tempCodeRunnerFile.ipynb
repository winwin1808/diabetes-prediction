# Load and preprocess your diabetes dataset
df_my = diabetes_data.copy()
X = df_my.iloc[:, :-1].values
y = df_my.iloc[:, -1].values
y = pd.get_dummies(y)
norm = StandardScaler()
X = norm.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Further split your training data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)

# Convert validation data to PyTorch tensors
X_val_tensor = torch.FloatTensor(X_val)
y_val_tensor = torch.FloatTensor(y_val.values)

# Define a more complex RNN model
class RNN(nn.Module):
    def __init__(self, input_size, hidden_layer_size=100, output_size=1, num_layers=3, dropout_rate=0.5):
        super(RNN, self).__init__()
        self.hidden_layer_size = hidden_layer_size
        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=num_layers, dropout=dropout_rate)
        self.bn1 = nn.BatchNorm1d(hidden_layer_size)
        self.linear = nn.Linear(hidden_layer_size, output_size)

    def forward(self, input_seq):
        lstm_out, _ = self.lstm(input_seq)
        x = self.bn1(lstm_out[:, -1])
        predictions = self.linear(x)
        return predictions
# Define hyperparameters for the more complex model
input_size = X_train.shape[1]
output_size = y_train.shape[1]
sequence_length = 1

hyperparameters = {
    'hidden_size': [64, 128, 256],
    'num_layers': [2, 4, 6],
    'learning_rate': [0.01, 0.02, 0.05],
    'num_epochs': [50, 100]
}

# Initialize best validation loss to infinity
best_val_loss = float('inf')

# You can iterate over the hyperparameters for grid search or random search
for hidden_size in hyperparameters['hidden_size']:
    for num_layers in hyperparameters['num_layers']:
        for learning_rate in hyperparameters['learning_rate']:
            for num_epochs in hyperparameters['num_epochs']:
                # Convert data to PyTorch tensors
                X_train_tensor = torch.FloatTensor(X_train).unsqueeze(1)
                y_train_tensor = torch.FloatTensor(y_train.values).unsqueeze(1)

                # Create the more complex RNN model
                model = RNN(input_size, hidden_size, output_size, num_layers)

                # Loss and optimizer
                criterion = nn.MSELoss()
                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

                # Training loop
                for epoch in range(num_epochs):
                    # Train for one epoch
                    model.train()
                    outputs = model(X_train_tensor)
                    optimizer.zero_grad()
                    loss = criterion(outputs, y_train_tensor)
                    loss.backward()
                    optimizer.step()

                    # Evaluate on validation set
                    model.eval()
                    with torch.no_grad():
                        val_outputs = model(X_val_tensor.unsqueeze(1))
                        val_loss = criterion(val_outputs, y_val_tensor.unsqueeze(1))

                    # If this model is better, save it
                    if val_loss < best_val_loss:
                        best_val_loss = val_loss
                        torch.save(model.state_dict(), 'best_model.pth')

                    # Print progress
                    if (epoch + 1) % 10 == 0:
                        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')

# Load the best model
model.load_state_dict(torch.load('best_model.pth'))

# Test the best model
with torch.no_grad():
    test_input = torch.FloatTensor(X_test).unsqueeze(1)
    predicted_output = model(test_input)
    print("Predicted Output Shape:", predicted_output.shape)
